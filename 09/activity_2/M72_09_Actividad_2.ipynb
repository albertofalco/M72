{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertofalco/M72/blob/main/M72_09_Actividad_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ME72: Maestría en Métodos Cuantitativos para la Gestión y Análisis de Datos\n",
        "M72109: Gestión de datos no estructurados\n",
        "Universidad de Buenos Aires - Facultad de Ciencias Economicas (UBA-FCE)\n",
        "Año: 2023\n",
        "\n",
        "Profesor: Facundo Santiago\n",
        "\n",
        "Alumno: Alberto Falco\n",
        "```"
      ],
      "metadata": {
        "id": "UExpWtNwppiB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQGxT74Sdis4"
      },
      "source": [
        "Actividad 2: Modelos basados en secuencias con Word2Vec\n",
        "======================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMwA8mhCZ4It"
      },
      "source": [
        "Introducción\n",
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjuHJnQOdis6"
      },
      "source": [
        "Los modelos basados en secuencias tienen la fortaleza que toman una secuencia de token (en un determinado orden) y generan una salida dependiendo del tipo de problema que se trate.\n",
        " - Seq2Class: Toman una secuencia de tokens y generan una clase\n",
        " - Seq2Seq: Toman una secuencia de token y generan otra secuencia de tokens.\n",
        "\n",
        "Vimos como podemos generar un modelo de secuencia utilizando `Word2Vec` y redes LSTM. Sin embargo ¿Les parece que conseguimos una buena performance?\n",
        "\n",
        "En esta actividad les proponemos ver como podemos mejorar la performance de este modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcyc_TQ6dis7"
      },
      "source": [
        "### Para ejecutar este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q__k723CZ4Iu"
      },
      "source": [
        "Para ejecutar este notebook, instale las siguientes librerias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKuX0IFbZ4Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaee9054-d11e-4678-dc31-f6588c17696f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/235.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/NLP/Datasets/mascorpus/tweets_marketing.csv \\\n",
        "    --quiet --no-clobber --directory-prefix ./Datasets/mascorpus/\n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/m72109/nlp/normalization.py \\\n",
        "    --quiet --no-clobber --directory-prefix ./m72109/nlp/\n",
        "!wget https://raw.githubusercontent.com/santiagxf/M72109/master/m72109/nlp/transformation.py \\\n",
        "    --quiet --no-clobber --directory-prefix ./m72109/nlp/\n",
        "\n",
        "!wget https://raw.githubusercontent.com/albertofalco/M72/main/09/activity_2/requirements.txt \\\n",
        "    --quiet --no-clobber\n",
        "!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl18LLmkeqjx"
      },
      "source": [
        "Descargamos nuestros vectores de word2vec en español"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJVkiH2lesN1"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./Models/Word2Vec\n",
        "!wget https://santiagxf.blob.core.windows.net/public/Word2Vec/model-es.bin \\\n",
        "    --quiet --no-clobber --directory-prefix ./Models/Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ntcs1AlpfckX"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rRpBRahditI"
      },
      "source": [
        "Instalamos las librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgVf9-V7ditI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3b36ad-6029-4f94-ec26-b91e62be7bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-27 15:57:05.540877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-27 15:57:05.540944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-27 15:57:05.540981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-27 15:57:05.548793: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-27 15:57:06.665718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-27 15:57:08.374421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-27 15:57:08.374965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-27 15:57:08.375171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Collecting es-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.6.0/es_core_news_sm-3.6.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC7vGpjqditL"
      },
      "source": [
        "Cargamos el set de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmJpenUkditM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv('Datasets/mascorpus/tweets_marketing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKrEadrGditO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets['TEXTO'], tweets['SECTOR'],\n",
        "                                                    test_size=0.33,\n",
        "                                                    stratify=tweets['SECTOR'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleOq8oVZ4Ix"
      },
      "source": [
        "Direcciones\n",
        "-----------\n",
        "\n",
        "¿Como puede hacer para mejorar la performance del modelo original que creamos en clase? Explore diferentes alternativas que lo llevarán a una mejor performance. En particular:\n",
        "\n",
        "- Remplazar la capa LSTM por una capa de tipo bidireccional. ¿Mejora?\n",
        "- ¿Que sucede con el pre-procesamiento? ¿Serviría modificar algo?\n",
        "    - Pista: Explore los parámteros de TweetNormalizer\n",
        "    \n",
        "Haga las modificaciones que crea pertinente y revise que propuestas mejoran la performance. Utilice la siguiente estructura de solución como ayuda, pero sientase libre de explorar otra.\n",
        "\n",
        "> **Importante:** No es necesario realizar tuneo de hiper-parametros para resolver este ejercicio, solo utilice su intuición para introducir modificaciones que deberían de llevarlo a un mejor resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4kHmpOHZ4Ix"
      },
      "source": [
        "Iteración 1: Original\n",
        "---------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnuzl8qbditU"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento de texto\n",
        "from m72109.nlp.normalization import TweetTextNormalizer\n",
        "\n",
        "normalizer = TweetTextNormalizer(preserve_case=False,\n",
        "                                 return_tokens=True,\n",
        "                                 language='spanish'\n",
        "                                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE-SlBWddite"
      },
      "outputs": [],
      "source": [
        "# Vectorización de las palabras\n",
        "from m72109.nlp.transformation import Word2VecVectorizer\n",
        "\n",
        "w2v = Word2VecVectorizer(model='Models/Word2Vec/model-es.bin', sequence_to_idx=True)\n",
        "embedding_weights = w2v.get_weights()\n",
        "\n",
        "embedding_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeVilfLMdit7"
      },
      "outputs": [],
      "source": [
        "# Ajustando la longitud de las secuencias\n",
        "from m72109.nlp.transformation import PadSequenceTransformer\n",
        "\n",
        "max_seq_len = 100\n",
        "seq2seq = PadSequenceTransformer(max_len=max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ2C980jditp"
      },
      "outputs": [],
      "source": [
        "# Construirmos un modelo basado en secuencias\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, SpatialDropout1D\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "def build_model(sequence_len, vocab_size, emdedding_size, embedding_weights):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, emdedding_size,\n",
        "                  weights=[embedding_weights],\n",
        "                  trainable=False,\n",
        "                  mask_zero=True),\n",
        "        SpatialDropout1D(0.2),\n",
        "        LSTM(emdedding_size),\n",
        "        Dense(7, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Wrapper de SciKeras.\n",
        "estimator = KerasClassifier(\n",
        "    build_fn=build_model,\n",
        "    epochs=50,\n",
        "    sequence_len=max_seq_len,\n",
        "    vocab_size=w2v.vocab_size,\n",
        "    emdedding_size=w2v.emdedding_size,\n",
        "    embedding_weights=embedding_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0V5zF-wdiuB"
      },
      "outputs": [],
      "source": [
        "# Creando nuestro pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline(steps=[('normalizer', normalizer),\n",
        "                           ('vectorizer', w2v),\n",
        "                           ('padder', seq2seq),\n",
        "                           ('estimator', estimator)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJYPslBwdiuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e6e7a0-6962-4a01-d90d-7e48a18e5c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2521/2521 [03:14<00:00, 12.99it/s]\n",
            "100%|██████████| 2521/2521 [00:00<00:00, 53132.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "79/79 [==============================] - 13s 91ms/step - loss: 1.3731 - accuracy: 0.5351\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 0.7332 - accuracy: 0.7921\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5519 - accuracy: 0.8417\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.4776 - accuracy: 0.8600\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 0.4098 - accuracy: 0.8758\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 9s 111ms/step - loss: 0.3547 - accuracy: 0.8893\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 9s 110ms/step - loss: 0.3268 - accuracy: 0.8969\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.3126 - accuracy: 0.9036\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.2877 - accuracy: 0.9143\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.2722 - accuracy: 0.9167\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 0.2530 - accuracy: 0.9171\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.2458 - accuracy: 0.9211\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 0.2304 - accuracy: 0.9234\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 11s 133ms/step - loss: 0.2192 - accuracy: 0.9258\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 0.2180 - accuracy: 0.9278\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 0.1999 - accuracy: 0.9385\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.2008 - accuracy: 0.9334\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 0.1920 - accuracy: 0.9413\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.1855 - accuracy: 0.9389\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.1893 - accuracy: 0.9369\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 0.1655 - accuracy: 0.9496\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 0.1626 - accuracy: 0.9472\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 8s 108ms/step - loss: 0.1465 - accuracy: 0.9532\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.1455 - accuracy: 0.9568\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 0.1363 - accuracy: 0.9540\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.1307 - accuracy: 0.9556\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.1185 - accuracy: 0.9576\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.1330 - accuracy: 0.9556\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 0.1166 - accuracy: 0.9615\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 0.1189 - accuracy: 0.9635\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.1139 - accuracy: 0.9663\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.1117 - accuracy: 0.9655\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 9s 109ms/step - loss: 0.0932 - accuracy: 0.9679\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 9s 110ms/step - loss: 0.0880 - accuracy: 0.9734\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 0.0972 - accuracy: 0.9718\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.0951 - accuracy: 0.9722\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.0900 - accuracy: 0.9710\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.0797 - accuracy: 0.9718\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.0750 - accuracy: 0.9758\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 0.0659 - accuracy: 0.9806\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.0643 - accuracy: 0.9774\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 0.0672 - accuracy: 0.9794\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.0604 - accuracy: 0.9829\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 9s 110ms/step - loss: 0.0615 - accuracy: 0.9821\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 0.0556 - accuracy: 0.9833\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 10s 120ms/step - loss: 0.0585 - accuracy: 0.9821\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 8s 105ms/step - loss: 0.0554 - accuracy: 0.9849\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 0.0609 - accuracy: 0.9829\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 0.0608 - accuracy: 0.9833\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 0.0486 - accuracy: 0.9861\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento.\n",
        "model = pipeline.fit(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqM4G2BVdiuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788a21ae-054a-4982-8ad7-4ed74dc84383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1242/1242 [01:30<00:00, 13.71it/s]\n",
            "100%|██████████| 1242/1242 [00:00<00:00, 63485.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 4s 45ms/step\n"
          ]
        }
      ],
      "source": [
        "# Obtención de predicciones.\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSIlnu1zdiuN",
        "outputId": "4a03798a-ae13-4c0f-e3d0-f8bbbc3a2910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "ALIMENTACION       0.95      0.92      0.94       110\n",
            "  AUTOMOCION       0.87      0.94      0.90       148\n",
            "       BANCA       0.92      0.92      0.92       198\n",
            "     BEBIDAS       0.85      0.93      0.89       223\n",
            "    DEPORTES       0.93      0.95      0.94       216\n",
            "      RETAIL       0.97      0.85      0.91       268\n",
            "       TELCO       0.86      0.87      0.87        79\n",
            "\n",
            "    accuracy                           0.91      1242\n",
            "   macro avg       0.91      0.91      0.91      1242\n",
            "weighted avg       0.91      0.91      0.91      1242\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtención de métricas.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo de referencia arrojó una métrica general de accuracy igual a 0.91."
      ],
      "metadata": {
        "id": "206QRCfM4ROD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteración 2: Ajustes sobre el preprocesamiento\n",
        "---------"
      ],
      "metadata": {
        "id": "qM38XhSM3W1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de librerias.\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, SpatialDropout1D\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from m72109.nlp.normalization import TweetTextNormalizer\n",
        "from m72109.nlp.transformation import Word2VecVectorizer\n",
        "from m72109.nlp.transformation import PadSequenceTransformer"
      ],
      "metadata": {
        "id": "lAnR8YMuzRZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup.\n",
        "normalizer = TweetTextNormalizer(preserve_case=False,\n",
        "                                 return_tokens=True,\n",
        "                                 language='spanish',\n",
        "                                 lemmatize=False, # Se modifica por False.\n",
        "                                 stem=False,\n",
        "                                 reduce_len=False, # Se modifica por False.\n",
        "                                 strip_handles=True,\n",
        "                                 strip_stopwords=True,\n",
        "                                 strip_urls=True,\n",
        "                                 strip_accents=True,\n",
        "                                 token_min_len=-1\n",
        "                                 )\n",
        "\n",
        "w2v = Word2VecVectorizer(model='Models/Word2Vec/model-es.bin', sequence_to_idx=True)\n",
        "embedding_weights = w2v.get_weights()\n",
        "\n",
        "max_seq_len = 100\n",
        "seq2seq = PadSequenceTransformer(max_len=max_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocJOVr7mcnX8",
        "outputId": "e8e587bc-f22e-459b-ea71-6e2369121935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
            "  warnings.warn(\n",
            "100%|██████████| 2656058/2656058 [00:07<00:00, 361465.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construccion del modelo.\n",
        "def build_model(sequence_len, vocab_size, emdedding_size, embedding_weights):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, emdedding_size,\n",
        "                  weights=[embedding_weights],\n",
        "                  trainable=False,\n",
        "                  mask_zero=True),\n",
        "        SpatialDropout1D(0.2),\n",
        "        LSTM(emdedding_size),\n",
        "        Dense(7, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Wrapper de Scikeras.\n",
        "estimator = KerasClassifier(\n",
        "    build_fn=build_model,\n",
        "    epochs=50,\n",
        "    sequence_len=max_seq_len,\n",
        "    vocab_size=w2v.vocab_size,\n",
        "    emdedding_size=w2v.emdedding_size,\n",
        "    embedding_weights=embedding_weights)\n",
        "\n",
        "# Construcción del pipeline.\n",
        "pipeline = Pipeline(steps=[('normalizer', normalizer),\n",
        "                           ('vectorizer', w2v),\n",
        "                           ('padder', seq2seq),\n",
        "                           ('estimator', estimator)])"
      ],
      "metadata": {
        "id": "g6Vad-DNcV3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento.\n",
        "model = pipeline.fit(X=X_train, y=y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbMvH467i-GZ",
        "outputId": "19e26458-99a4-41ad-ecb4-184d6a0390f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2521/2521 [00:00<00:00, 3665.13it/s]\n",
            "100%|██████████| 2521/2521 [00:00<00:00, 33661.04it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "79/79 [==============================] - 30s 235ms/step - loss: 1.2844 - accuracy: 0.5649\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 22s 270ms/step - loss: 0.5908 - accuracy: 0.8306\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.4206 - accuracy: 0.8743\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 0.3619 - accuracy: 0.8862\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 20s 254ms/step - loss: 0.2977 - accuracy: 0.9123\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 0.2745 - accuracy: 0.9115\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 19s 245ms/step - loss: 0.2447 - accuracy: 0.9242\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 20s 249ms/step - loss: 0.2188 - accuracy: 0.9290\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 0.1969 - accuracy: 0.9357\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 0.1848 - accuracy: 0.9357\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 20s 245ms/step - loss: 0.1802 - accuracy: 0.9433\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.1700 - accuracy: 0.9476\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 20s 247ms/step - loss: 0.1447 - accuracy: 0.9516\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 0.1519 - accuracy: 0.9532\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.1524 - accuracy: 0.9484\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 0.1435 - accuracy: 0.9532\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 19s 244ms/step - loss: 0.1332 - accuracy: 0.9595\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.1117 - accuracy: 0.9643\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 0.1128 - accuracy: 0.9623\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 20s 249ms/step - loss: 0.1105 - accuracy: 0.9655\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 0.1294 - accuracy: 0.9587\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 0.1092 - accuracy: 0.9627\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 0.0929 - accuracy: 0.9714\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 0.0915 - accuracy: 0.9699\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 0.1005 - accuracy: 0.9671\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 0.0923 - accuracy: 0.9726\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.0811 - accuracy: 0.9746\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 0.0812 - accuracy: 0.9706\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 20s 249ms/step - loss: 0.0733 - accuracy: 0.9774\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.0680 - accuracy: 0.9802\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 0.0754 - accuracy: 0.9778\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 20s 254ms/step - loss: 0.0572 - accuracy: 0.9833\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 0.0581 - accuracy: 0.9833\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 0.0606 - accuracy: 0.9829\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 20s 258ms/step - loss: 0.0634 - accuracy: 0.9821\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 0.0578 - accuracy: 0.9786\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 0.0585 - accuracy: 0.9810\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 20s 255ms/step - loss: 0.0485 - accuracy: 0.9877\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 0.0576 - accuracy: 0.9818\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 0.0627 - accuracy: 0.9790\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 20s 257ms/step - loss: 0.0589 - accuracy: 0.9810\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 18s 227ms/step - loss: 0.0374 - accuracy: 0.9901\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.0356 - accuracy: 0.9885\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 20s 251ms/step - loss: 0.0329 - accuracy: 0.9905\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 0.0320 - accuracy: 0.9917\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 0.0374 - accuracy: 0.9881\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 20s 255ms/step - loss: 0.0346 - accuracy: 0.9881\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 0.0268 - accuracy: 0.9933\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 0.0314 - accuracy: 0.9929\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 20s 253ms/step - loss: 0.0318 - accuracy: 0.9889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención de resultados.\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB32cq-2o1VE",
        "outputId": "9a234bf3-979a-45ca-9d30-395a11a7c4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1242/1242 [00:00<00:00, 3701.03it/s]\n",
            "100%|██████████| 1242/1242 [00:00<00:00, 109552.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 1s 23ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "ALIMENTACION       0.98      0.97      0.98       110\n",
            "  AUTOMOCION       0.95      0.97      0.96       148\n",
            "       BANCA       0.95      0.94      0.95       198\n",
            "     BEBIDAS       0.89      0.96      0.92       223\n",
            "    DEPORTES       0.98      0.92      0.95       216\n",
            "      RETAIL       0.94      0.94      0.94       268\n",
            "       TELCO       0.99      0.95      0.97        79\n",
            "\n",
            "    accuracy                           0.95      1242\n",
            "   macro avg       0.96      0.95      0.95      1242\n",
            "weighted avg       0.95      0.95      0.95      1242\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de la modificación en el preprocesamiento (desactivación del lemmatizer y sin corte de longitudes de secuencias), el nuevo modelo arrojó una métrica general de accuracy igual a 0.95."
      ],
      "metadata": {
        "id": "alEsdDNU4Yy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteración 3: Ajustes sobre el modelo. Utilización de dropout adicional.\n",
        "---------"
      ],
      "metadata": {
        "id": "4tSor4nOpQpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de librerias.\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, SpatialDropout1D, Dropout\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from m72109.nlp.normalization import TweetTextNormalizer\n",
        "from m72109.nlp.transformation import Word2VecVectorizer\n",
        "from m72109.nlp.transformation import PadSequenceTransformer"
      ],
      "metadata": {
        "id": "DicQT39sv5Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup.\n",
        "normalizer = TweetTextNormalizer(preserve_case=False,\n",
        "                                 return_tokens=True,\n",
        "                                 language='spanish',\n",
        "                                 lemmatize=False, # Se modifica por False.\n",
        "                                 stem=False,\n",
        "                                 reduce_len=False, # Se modifica por False.\n",
        "                                 strip_handles=True,\n",
        "                                 strip_stopwords=True,\n",
        "                                 strip_urls=True,\n",
        "                                 strip_accents=True,\n",
        "                                 token_min_len=-1\n",
        "                                 )\n",
        "\n",
        "# Instanciación del vectorizer y obtención de pesos.\n",
        "w2v = Word2VecVectorizer(model='Models/Word2Vec/model-es.bin', sequence_to_idx=True)\n",
        "embedding_weights = w2v.get_weights()\n",
        "\n",
        "# Padding.\n",
        "max_seq_len = 100\n",
        "seq2seq = PadSequenceTransformer(max_len=max_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSJ5t0R_v5OJ",
        "outputId": "b27d46a7-c461-4842-af09-47f9b68b172c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2656058/2656058 [00:06<00:00, 425323.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construccion del modelo.\n",
        "def build_model(sequence_len, vocab_size, emdedding_size, embedding_weights):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, emdedding_size,\n",
        "                  weights=[embedding_weights],\n",
        "                  trainable=False,\n",
        "                  mask_zero=True),\n",
        "        SpatialDropout1D(0.2),\n",
        "        LSTM(emdedding_size),\n",
        "        Dropout(0.1), # Se incorpora una segunda capa de dropout convencional luego de LSTM.\n",
        "        Dense(7, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Wrapper de Scikeras.\n",
        "estimator = KerasClassifier(\n",
        "    build_fn=build_model,\n",
        "    epochs=50,\n",
        "    sequence_len=max_seq_len,\n",
        "    vocab_size=w2v.vocab_size,\n",
        "    emdedding_size=w2v.emdedding_size,\n",
        "    embedding_weights=embedding_weights)\n",
        "\n",
        "# Construcción del pipeline.\n",
        "pipeline = Pipeline(steps=[('normalizer', normalizer),\n",
        "                           ('vectorizer', w2v),\n",
        "                           ('padder', seq2seq),\n",
        "                           ('estimator', estimator)])"
      ],
      "metadata": {
        "id": "IUYgAWuZv5Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento.\n",
        "model = pipeline.fit(X=X_train, y=y_train)"
      ],
      "metadata": {
        "id": "v_MfHVukv5Io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd9fe47-7c9b-486b-ced8-380bc2c2963a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2521/2521 [00:00<00:00, 7032.07it/s]\n",
            "100%|██████████| 2521/2521 [00:00<00:00, 164294.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "79/79 [==============================] - 25s 264ms/step - loss: 1.2671 - accuracy: 0.5930\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 18s 235ms/step - loss: 0.6300 - accuracy: 0.8167\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 0.4654 - accuracy: 0.8584\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 20s 257ms/step - loss: 0.3578 - accuracy: 0.8889\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 0.2841 - accuracy: 0.9084\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 20s 252ms/step - loss: 0.2781 - accuracy: 0.9143\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 0.2388 - accuracy: 0.9314\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 0.2246 - accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 21s 268ms/step - loss: 0.2015 - accuracy: 0.9353\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.1649 - accuracy: 0.9457\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 20s 251ms/step - loss: 0.1889 - accuracy: 0.9373\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 20s 249ms/step - loss: 0.1781 - accuracy: 0.9453\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.1591 - accuracy: 0.9492\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 20s 260ms/step - loss: 0.1439 - accuracy: 0.9516\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 0.1533 - accuracy: 0.9480\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 19s 241ms/step - loss: 0.1295 - accuracy: 0.9548\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 23s 294ms/step - loss: 0.1312 - accuracy: 0.9615\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 0.1265 - accuracy: 0.9603\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 21s 270ms/step - loss: 0.1154 - accuracy: 0.9627\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 20s 248ms/step - loss: 0.1107 - accuracy: 0.9611\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 21s 264ms/step - loss: 0.1025 - accuracy: 0.9667\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 0.1000 - accuracy: 0.9687\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 0.1053 - accuracy: 0.9675\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 21s 265ms/step - loss: 0.0887 - accuracy: 0.9683\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 19s 243ms/step - loss: 0.0838 - accuracy: 0.9750\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 21s 270ms/step - loss: 0.0806 - accuracy: 0.9754\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.0860 - accuracy: 0.9706\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 0.0685 - accuracy: 0.9782\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 21s 262ms/step - loss: 0.0894 - accuracy: 0.9691\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 0.0780 - accuracy: 0.9778\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 21s 262ms/step - loss: 0.0763 - accuracy: 0.9774\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 0.0552 - accuracy: 0.9825\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 0.0584 - accuracy: 0.9829\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 21s 263ms/step - loss: 0.0584 - accuracy: 0.9802\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 0.0597 - accuracy: 0.9802\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.0576 - accuracy: 0.9849\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 21s 265ms/step - loss: 0.0479 - accuracy: 0.9861\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 0.0509 - accuracy: 0.9837\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 21s 260ms/step - loss: 0.0489 - accuracy: 0.9861\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 0.0541 - accuracy: 0.9845\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 0.0437 - accuracy: 0.9869\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 21s 266ms/step - loss: 0.0442 - accuracy: 0.9873\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 19s 241ms/step - loss: 0.0342 - accuracy: 0.9909\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 20s 254ms/step - loss: 0.0540 - accuracy: 0.9821\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 20s 252ms/step - loss: 0.0404 - accuracy: 0.9885\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 0.0376 - accuracy: 0.9889\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 22s 273ms/step - loss: 0.0364 - accuracy: 0.9893\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 0.0360 - accuracy: 0.9865\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 20s 256ms/step - loss: 0.0365 - accuracy: 0.9893\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 19s 244ms/step - loss: 0.0303 - accuracy: 0.9909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención de resultados.\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "AMuJs1RRv5F9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6be2e7d-a870-4446-8101-153046b86ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1242/1242 [00:00<00:00, 7573.90it/s]\n",
            "100%|██████████| 1242/1242 [00:00<00:00, 169967.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 2s 19ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "ALIMENTACION       0.95      0.95      0.95       110\n",
            "  AUTOMOCION       0.97      0.97      0.97       148\n",
            "       BANCA       0.91      0.94      0.93       198\n",
            "     BEBIDAS       0.93      0.93      0.93       223\n",
            "    DEPORTES       0.96      0.95      0.96       216\n",
            "      RETAIL       0.93      0.93      0.93       268\n",
            "       TELCO       0.97      0.96      0.97        79\n",
            "\n",
            "    accuracy                           0.94      1242\n",
            "   macro avg       0.95      0.95      0.95      1242\n",
            "weighted avg       0.94      0.94      0.94      1242\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de la modificación en el preprocesamiento y utilizando una capa adicional de dropout luego de la capa LSTM, el nuevo modelo arrojó una métrica levemente inferior al anterior, con un accuracy igual a 0.94."
      ],
      "metadata": {
        "id": "U2A6Hq2p4wgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteración 4: Ajustes sobre el modelo. Uso de redes recurrentes bidireccionales.\n",
        "---------"
      ],
      "metadata": {
        "id": "evsrZKs-qc8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de librerias.\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, SpatialDropout1D, Dropout, Bidirectional\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from m72109.nlp.normalization import TweetTextNormalizer\n",
        "from m72109.nlp.transformation import Word2VecVectorizer\n",
        "from m72109.nlp.transformation import PadSequenceTransformer"
      ],
      "metadata": {
        "id": "lh9YpC-owDII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup.\n",
        "normalizer = TweetTextNormalizer(preserve_case=False,\n",
        "                                 return_tokens=True,\n",
        "                                 language='spanish',\n",
        "                                 lemmatize=False, # Se modifica por False.\n",
        "                                 stem=False,\n",
        "                                 reduce_len=False, # Se modifica por False.\n",
        "                                 strip_handles=True,\n",
        "                                 strip_stopwords=True,\n",
        "                                 strip_urls=True,\n",
        "                                 strip_accents=True,\n",
        "                                 token_min_len=-1\n",
        "                                 )\n",
        "\n",
        "# Instanciación del vectorizer y obtención de pesos.\n",
        "w2v = Word2VecVectorizer(model='Models/Word2Vec/model-es.bin', sequence_to_idx=True)\n",
        "embedding_weights = w2v.get_weights()\n",
        "\n",
        "# Padding.\n",
        "max_seq_len = 100\n",
        "seq2seq = PadSequenceTransformer(max_len=max_seq_len)"
      ],
      "metadata": {
        "id": "Fpq8AVI2wDEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construccion del modelo.\n",
        "def build_model(sequence_len, vocab_size, emdedding_size, embedding_weights):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, emdedding_size,\n",
        "                  weights=[embedding_weights],\n",
        "                  trainable=False,\n",
        "                  mask_zero=True),\n",
        "        SpatialDropout1D(0.2),\n",
        "        Bidirectional(LSTM(emdedding_size)), # Se embebe la capa LSTM dentro de la Bidirectional.\n",
        "        Dropout(0.1), # Se incorpora una segunda capa de dropout convencional luego de LSTM.\n",
        "        Dense(7, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Wrapper de Scikeras.\n",
        "estimator = KerasClassifier(\n",
        "    build_fn=build_model,\n",
        "    epochs=50,\n",
        "    sequence_len=max_seq_len,\n",
        "    vocab_size=w2v.vocab_size,\n",
        "    emdedding_size=w2v.emdedding_size,\n",
        "    embedding_weights=embedding_weights)\n",
        "\n",
        "# Construcción del pipeline.\n",
        "pipeline = Pipeline(steps=[('normalizer', normalizer),\n",
        "                           ('vectorizer', w2v),\n",
        "                           ('padder', seq2seq),\n",
        "                           ('estimator', estimator)])"
      ],
      "metadata": {
        "id": "-XTOLxmrv5DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model = pipeline.fit(X=X_train, y=y_train)"
      ],
      "metadata": {
        "id": "AULJeoclxB4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4850ec17-8d76-468f-c1b9-d949ea728354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2521/2521 [00:00<00:00, 6578.03it/s]\n",
            "100%|██████████| 2521/2521 [00:00<00:00, 148080.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "79/79 [==============================] - 48s 486ms/step - loss: 1.1501 - accuracy: 0.6311\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 36s 458ms/step - loss: 0.5109 - accuracy: 0.8520\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 35s 443ms/step - loss: 0.3987 - accuracy: 0.8762\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 37s 463ms/step - loss: 0.3139 - accuracy: 0.9000\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 34s 435ms/step - loss: 0.2741 - accuracy: 0.9155\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 35s 443ms/step - loss: 0.2398 - accuracy: 0.9187\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 35s 439ms/step - loss: 0.2166 - accuracy: 0.9349\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 35s 445ms/step - loss: 0.1982 - accuracy: 0.9334\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 34s 433ms/step - loss: 0.1952 - accuracy: 0.9326\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 34s 430ms/step - loss: 0.1649 - accuracy: 0.9472\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 35s 444ms/step - loss: 0.1522 - accuracy: 0.9480\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 34s 431ms/step - loss: 0.1353 - accuracy: 0.9540\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 36s 454ms/step - loss: 0.1366 - accuracy: 0.9528\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 34s 432ms/step - loss: 0.1201 - accuracy: 0.9599\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 35s 446ms/step - loss: 0.1233 - accuracy: 0.9599\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 34s 426ms/step - loss: 0.1139 - accuracy: 0.9576\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 36s 456ms/step - loss: 0.1129 - accuracy: 0.9659\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 34s 428ms/step - loss: 0.0868 - accuracy: 0.9754\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 35s 449ms/step - loss: 0.0934 - accuracy: 0.9695\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 33s 418ms/step - loss: 0.0901 - accuracy: 0.9699\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 34s 432ms/step - loss: 0.0858 - accuracy: 0.9695\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 34s 429ms/step - loss: 0.0880 - accuracy: 0.9671\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 32s 409ms/step - loss: 0.0824 - accuracy: 0.9706\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 34s 426ms/step - loss: 0.0620 - accuracy: 0.9825\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 32s 409ms/step - loss: 0.0583 - accuracy: 0.9837\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 33s 420ms/step - loss: 0.0613 - accuracy: 0.9774\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 34s 425ms/step - loss: 0.0528 - accuracy: 0.9821\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 33s 412ms/step - loss: 0.0513 - accuracy: 0.9806\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 34s 431ms/step - loss: 0.0584 - accuracy: 0.9806\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 33s 424ms/step - loss: 0.0476 - accuracy: 0.9837\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 33s 416ms/step - loss: 0.0468 - accuracy: 0.9881\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 34s 432ms/step - loss: 0.0422 - accuracy: 0.9869\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 33s 415ms/step - loss: 0.0454 - accuracy: 0.9829\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 33s 418ms/step - loss: 0.0439 - accuracy: 0.9861\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 33s 422ms/step - loss: 0.0264 - accuracy: 0.9940\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 33s 412ms/step - loss: 0.0434 - accuracy: 0.9865\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 34s 425ms/step - loss: 0.0313 - accuracy: 0.9901\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 34s 425ms/step - loss: 0.0293 - accuracy: 0.9909\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 33s 412ms/step - loss: 0.0261 - accuracy: 0.9921\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 33s 422ms/step - loss: 0.0253 - accuracy: 0.9925\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 33s 415ms/step - loss: 0.0272 - accuracy: 0.9929\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 34s 424ms/step - loss: 0.0243 - accuracy: 0.9940\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 34s 429ms/step - loss: 0.0241 - accuracy: 0.9925\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 33s 415ms/step - loss: 0.0354 - accuracy: 0.9889\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 34s 427ms/step - loss: 0.0303 - accuracy: 0.9909\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 34s 432ms/step - loss: 0.0188 - accuracy: 0.9956\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 33s 419ms/step - loss: 0.0311 - accuracy: 0.9913\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 34s 431ms/step - loss: 0.0500 - accuracy: 0.9865\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 34s 435ms/step - loss: 0.0278 - accuracy: 0.9929\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 33s 419ms/step - loss: 0.0165 - accuracy: 0.9964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtención de resultados.\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "xkTPf1UqxB1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e70a33-6796-4f49-aef4-a067cb61a317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1242/1242 [00:00<00:00, 6984.91it/s]\n",
            "100%|██████████| 1242/1242 [00:00<00:00, 134444.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 5s 52ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "ALIMENTACION       0.98      0.94      0.96       110\n",
            "  AUTOMOCION       0.97      0.95      0.96       148\n",
            "       BANCA       0.92      0.94      0.93       198\n",
            "     BEBIDAS       0.91      0.92      0.92       223\n",
            "    DEPORTES       0.94      0.94      0.94       216\n",
            "      RETAIL       0.93      0.92      0.93       268\n",
            "       TELCO       0.96      0.95      0.96        79\n",
            "\n",
            "    accuracy                           0.94      1242\n",
            "   macro avg       0.94      0.94      0.94      1242\n",
            "weighted avg       0.94      0.94      0.94      1242\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las modificaciones en el preprocesamiento, la incorporación de una capa de dropout y la incorporación de una capa bidireccional sobre la capa LSTM, se obtuvo una métrica similar a la anterior."
      ],
      "metadata": {
        "id": "JHHqfkCM47dH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusiones\n",
        "---------"
      ],
      "metadata": {
        "id": "zE59dbbgyyxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De las iteraciones realizadas y los resultados obtenidos teniendo en cuenta las épocas de entrenamiento ejecutadas, se concluye que la principal mejora sobre el desempeño se obtuvo a partir de la modificación de los parámetros de preprocesamiento.\n",
        "\n",
        "En particular, a partir de la desactivación del lemmatizer y del corte de las longitudes de secuencias en la etapa de preprocesamiento, el nuevo modelo incrementó su perfomance, arrojando la mejor métrica general de accuracy obtenida, de 0.95."
      ],
      "metadata": {
        "id": "A9z87M3ey3Nv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X4kHmpOHZ4Ix",
        "qM38XhSM3W1p",
        "4tSor4nOpQpv",
        "evsrZKs-qc8g"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
